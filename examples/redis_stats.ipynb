{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import rich\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from sotopia.database.persistent_profile import AgentProfile, EnvironmentProfile, RelationshipProfile\n",
    "from sotopia.database.logs import EpisodeLog\n",
    "from sotopia.database.env_agent_combo_storage import EnvAgentComboStorage\n",
    "from collections import Counter \n",
    "from redis_om import Migrator\n",
    "from rich.console import Console\n",
    "from rich.terminal_theme import MONOKAI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_pks = RelationshipProfile.all_pks()\n",
    "res_pks = list(res_pks)\n",
    "print(len(res_pks))\n",
    "res = []\n",
    "for pk in res_pks:\n",
    "    print(pk)\n",
    "    try:\n",
    "        res.append(RelationshipProfile.get(pk=pk))\n",
    "    except:\n",
    "        print(\"error\")\n",
    "        pass\n",
    "res_relationships = [r.relationship for r in res]\n",
    "Counter(res_relationships)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain a specific agent\n",
    "agents = AgentProfile.find(AgentProfile.first_name == \"ss\").all()\n",
    "rich.print(agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find specific agnets\n",
    "agents = AgentProfile.find(AgentProfile.gender==\"Man\", AgentProfile.age>30)\n",
    "for agent in agents:\n",
    "    rich.print(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain all agents' basic info\n",
    "agent_pks = AgentProfile.all_pks()\n",
    "agent_pks = list(agent_pks)\n",
    "print(len(agent_pks))\n",
    "agents = []\n",
    "for pk in agent_pks:\n",
    "    try:\n",
    "        agents.append(AgentProfile.get(pk=pk))\n",
    "    except:\n",
    "        print(\"error\")\n",
    "        pass\n",
    "# output agents's basic info\n",
    "for agent in agents:\n",
    "    rich.print(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_pks = AgentProfile.all_pks()\n",
    "agent_pks = list(agent_pks)\n",
    "print(len(agent_pks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update agent's information\n",
    "agents = AgentProfile.find(AgentProfile.first_name == 'Ava', AgentProfile.last_name == 'Martinez').all()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents.update(secret = 'Keeps their bisexuality a secret from her conservative family')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all environments\n",
    "all_envs = list(EnvironmentProfile.all_pks())\n",
    "print(len(all_envs))\n",
    "print(all_envs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a specific environment profile\n",
    "env_profile_id = \"01H7VFHPJKR16MD1KC71V4ZRCF\"\n",
    "env = EnvironmentProfile.get(env_profile_id)\n",
    "rich.print(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EnvAgentComboStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all env-agent combos\n",
    "all_combos = EnvAgentComboStorage().all_pks()\n",
    "all_combos = list(all_combos)\n",
    "print(len(all_combos))\n",
    "rich.print(EnvAgentComboStorage().get(all_combos[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicates in EnvAgentComboStorage\n",
    "cache = set()\n",
    "for combo_pk in all_combos:\n",
    "    combo = EnvAgentComboStorage.get(combo_pk)\n",
    "    curr_tuple = (combo.env_id, combo.agent_ids[0], combo.agent_ids[1])\n",
    "    if curr_tuple in cache:\n",
    "        print(\"duplicate\")\n",
    "    else:\n",
    "        cache.add(curr_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episode Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find episode log by tag\n",
    "Episodes = EpisodeLog.find(EpisodeLog.tag == \"6_initial_aug14_full\").all()\n",
    "len(Episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all episode logs' primary keys\n",
    "episode_pks = EpisodeLog.all_pks()\n",
    "episode_pks = list(episode_pks)\n",
    "print(len(episode_pks))\n",
    "print(episode_pks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some eps have validation error while loading\n",
    "# please look at the buggy_eps list\n",
    "gpt35_llama2_eps = []\n",
    "buggy_eps = []\n",
    "for epid in episode_pks:\n",
    "    try:\n",
    "        curr_ep = EpisodeLog.get(epid)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        buggy_eps.append(curr_ep)\n",
    "        continue\n",
    "    gpt35_llama2_eps.append(curr_ep)\n",
    "len(gpt35_llama2_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the epilogs that contain the specified models\n",
    "model1 = 'gpt-3.5-turbo'\n",
    "model2 = 'togethercomputer/llama-2-70b-chat'\n",
    "model_comp1 = ['gpt-4', model1, model2]\n",
    "model_comp2 = ['gpt-4', model2, model1]\n",
    "\n",
    "gpt35_llama2_eps = []\n",
    "for epid in episode_pks:\n",
    "    try:\n",
    "        curr_ep = EpisodeLog.get(epid)\n",
    "    except:\n",
    "        continue\n",
    "    if curr_ep.models == model_comp1 or curr_ep.models == model_comp2:\n",
    "        gpt35_llama2_eps.append(curr_ep)\n",
    "len(gpt35_llama2_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check symetry of epilogs, i.e., if we have an epilog for env1, agent1, agent2, then we should have an epilog for env1, agent2, agent1\n",
    "def is_symmetric_epilogs(epilogs):\n",
    "    asymetric_epilogs = []\n",
    "    gpt35_llama2_epilogs_dict = {}\n",
    "    for ep in epilogs:\n",
    "        hash_key = (ep.environment, ep.agents[0], ep.agents[1], ep.models[0], ep.models[1], ep.models[2])\n",
    "        gpt35_llama2_epilogs_dict[hash_key] = ep.pk\n",
    "    for hash_key in gpt35_llama2_epilogs_dict:\n",
    "        if (hash_key[0], hash_key[1], hash_key[2], hash_key[3], hash_key[5], hash_key[4]) not in gpt35_llama2_epilogs_dict:\n",
    "            asymetric_epilogs.append(gpt35_llama2_epilogs_dict[hash_key])\n",
    "    \n",
    "    if len(asymetric_epilogs) == 0:\n",
    "        return True\n",
    "    else:\n",
    "        logging.warning(f\"Found {len(asymetric_epilogs)} asymetric epilogs: {asymetric_epilogs}\")\n",
    "        return False\n",
    "            \n",
    "    \n",
    "#export episode log to html\n",
    "def export_html_from_log(ep: EpisodeLog, file_path: str = \"./output.html\") -> None:\n",
    "    agent_profiles, conversation = ep.render_for_humans()\n",
    "    console = Console(record=True, log_time=False, log_path=False)\n",
    "    console.log(f\"Models:\\n Env: {ep.models[0]}\\n Agent1: {ep.models[1]}\\n Agent2: {ep.models[2]}\\n\")\n",
    "\n",
    "    for agent_profile in agent_profiles:\n",
    "        console.log(agent_profile)\n",
    "    for message in conversation:\n",
    "        console.log(message)\n",
    "    console.save_svg(file_path, theme=MONOKAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_symmetric_epilogs(Episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_html_from_log(gpt35_llama2_eps[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a human readable version of the episode\n",
    "agent_profiles, conversation = Episodes[1].render_for_humans()\n",
    "for agent_profile in agent_profiles:\n",
    "    rich.print(agent_profile)\n",
    "for message in conversation:\n",
    "    rich.print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check environments\n",
    "len(set([Episode.environment for Episode in Episodes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def get_avg_reward_for_models(episodes: list[EpisodeLog]) -> dict[str, dict[str, float]]:\n",
    "    \"\"\"Get the average reward for each model in the episodes.\n",
    "\n",
    "    Args:\n",
    "        episodes (list[EpisodeLog]): A list of episodes.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, float]: A dictionary mapping model names to average rewards.\n",
    "    \"\"\"\n",
    "    model_rewards = defaultdict(list)\n",
    "    model_rewards_avg = {}\n",
    "    for episode in episodes:\n",
    "        for idx, model in enumerate(episode.models[1:]): # skip env\n",
    "            print(model)\n",
    "            if isinstance(episode.rewards[idx], tuple):\n",
    "                model_rewards[model + '_agent_' + str(idx)].append(episode.rewards[idx])\n",
    "            else:\n",
    "                #rich.print(episode.render_for_humans())\n",
    "                print(episode.rewards)\n",
    "                #print(episode.rewards[idx])\n",
    "    for model in model_rewards:\n",
    "        model_rewards[model] = [rewards[1] for rewards in model_rewards[model]] \n",
    "        model_rewards_avg[model] = pd.DataFrame.from_dict(model_rewards[model])\n",
    "        model_rewards_avg[model] = model_rewards_avg[model].mean(axis=0).to_dict()\n",
    "    return pd.DataFrame.from_dict(model_rewards_avg)\n",
    "\n",
    "def get_avg_successRate_for_models(episodes: list[EpisodeLog]) -> dict[str, dict[str, float]]:\n",
    "    \"\"\"Get the average success rate for each model in the episodes.\n",
    "\n",
    "    Args:\n",
    "        episodes (list[EpisodeLog]): A list of episodes.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, float]: A dictionary mapping model names to average success rates.\n",
    "    \"\"\"\n",
    "    model_rewards = defaultdict(list)\n",
    "    model_successRate_avg = {}\n",
    "    for episode in episodes:\n",
    "        for idx, model in enumerate(episode.models[1:]): # skip env\n",
    "            if isinstance(episode.rewards[idx], tuple):\n",
    "                model_rewards[model + '_agent_' + str(idx)].append(episode.rewards[idx])\n",
    "            else:\n",
    "                #rich.print(episode.render_for_humans())\n",
    "                print(episode.rewards, episode.messages[0])\n",
    "                #print(episode.rewards[idx])\n",
    "    for model in model_rewards:\n",
    "        model_successRate_avg[model] = [rewards[1] for rewards in model_rewards[model]]\n",
    "        model_successRate_avg[model] = pd.DataFrame.from_dict(model_successRate_avg[model])\n",
    "    assert len(model_successRate_avg) == 2, \"There should be two models\"\n",
    "    model_list = list(model_successRate_avg.keys())\n",
    "    model_one_successRate = model_successRate_avg[model_list[0]] > model_successRate_avg[model_list[1]]\n",
    "    model_two_successRate = model_successRate_avg[model_list[0]] < model_successRate_avg[model_list[1]]\n",
    "    model_on_par_successRate = model_successRate_avg[model_list[0]] == model_successRate_avg[model_list[1]]\n",
    "    return pd.DataFrame.from_dict({\n",
    "        model_list[0]: model_one_successRate.mean(axis=0).to_dict(),\n",
    "        \"on_par\": model_on_par_successRate.mean(axis=0).to_dict(),\n",
    "        model_list[1]: model_two_successRate.mean(axis=0).to_dict(),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_avg_reward_for_models(Episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_avg_successRate_for_models(Episodes)\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sotopia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
